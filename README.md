# Вторая лабораторная работа по алгоритмам

Логин: pashamedvedev03 (pashamedvedev03@yandex.ru)

![image](https://user-images.githubusercontent.com/46136468/234573265-c372dfed-f5eb-449e-9df3-d0dd0fd605c6.png)

# Особенности проекта

Лабораторная выполнена на Java и собрана с помощью Gradle. Я отключил `just-in-time (JIT) compilation` для избежания кэширования часто используемых данных и оптимизации алгоритмов там, где это вовсе не нужно.

# Замеры производительности

## Сравнение продолжительности подготовки данных

Приведу обычный и логарифмический графики препроцессинга данных:

![prepare](https://user-images.githubusercontent.com/46136468/234573734-60cf06d3-9e1f-4bb8-b3dd-4ee2242f5f61.png)

![prepare_log](https://user-images.githubusercontent.com/46136468/234573745-52a1c7fd-c303-4075-81c6-001f545b9542.png)

**Переборный алгоритм**, судя по первому графику и значениям второго, практически не требует времени на подгтовку данных (не более `10000` наносекунд, либо `0.00001` секунд), что является очевидным - вся подготовка состоит в присваивании списка прямоугольников классу с решением.

Что насчёт **алгоритма на дереве**, он потребляет чуть больше времени, чем переборный алгоритм (вплоть до `0.1` секунды), но заметно меньше, чем алгоритм на карте из-за своей асимптотики: `O(N*logN)`.

Ну и, наконец, **алгоритм на карте** - самый большой потребитель ресурсов на подготовку входных данных. Сжатие координат и заполнение карты покрытий (в общей сложности `O(n^3)`) требуют огромного количества времени, в частности, около `5` (!) минут на входных данных в 2000 единиц. 

Я запускал тесты только до `2000` точек и прямоугольников, т.к. после этого значения мой компьютер (а ещё и с выключенной `JIT`) отказывался выдавать ответ в пределах разумного отрезка времени (p.s.: программе потребовалось **20 минут** на прогон 19 тестов с различными количеством элементов на карте для записи измерений).

График требуемого времени для алгоритма на карте и вправду очень похож на кубическую функцию, которая летит в потолок после 1000 входных точек и прямоугольников.

## Сравнение продолжительности работы алгоритмов

Снова приведу два вида графиков:

![execution](https://user-images.githubusercontent.com/46136468/234587139-9e08d3c5-1a6c-4576-9f4f-3c2bded3ed4d.png)

![execution_log](https://user-images.githubusercontent.com/46136468/234587202-6aff5f74-8423-4580-9067-7003e40868ce.png)

Обращая внимание на **переборный алгоритм** и не принимая в счёт небольшую просадку по времени работы на его старте, можно сказать, что решение работает за линейное время, что совпадает с заявленной сложностью данного алгоритма (`O(n)`).

Для **алгоритма на карте** требуется заметно меньшее количество времени для получения ответа, т.к. после затраты огромного количества ресурсов на построение карты мы получаем стуктуру (двумерный массив), из которой с помощью двоичного поиска по сжатым координатам за логарифмическую сложность мы и получаем заветное решение для данной точки.

**Алгоритм на дереве** требует немногим больше времени, чел алгоритм на карте, но всё же на порядок меньше, чем необходимо алгоритму перебора.

# Выводы

В случае, когда входных данных небольшое количество (до `250` точек и прямоугольников), существенной разницы между алгоритмами не существует:
* воспользуйтесь **переборным алгоритмом**, если во входных данных мало и прямоугольников, и точек, т.к. данный алгоритм невероятно простой, не требует нагруженных структур данных и отлично справляется со своей задачей в разумные временные рамки,
* воспользуйтесь **алгоритмом на карте**, если количество точек существенно превышает малый объём прямоугольников: на таком объёме карта строится довольно быстро и позволяет за логарифмическое время получить решение на задачу.

Не стоит пользоваться **алгоритмом на дереве** на малом массиве входных данных из-за его сложности в реализации, достаточно будет двух вышеописанных алгоритмов (*keep it simple stupid.*)

В остальных случаях, когда количество точек и прямоугольников переваливает за 500, стоит остановить свой выбор на **алгоритме на дереве**. Как построение, так и получение ответа на задачу имеют вычислительную сложность `O(N*logN)`, что позволяет нам и быстро подготовить необходимую стуктуру данных, и также за разумное время получить из неё ответ. 
